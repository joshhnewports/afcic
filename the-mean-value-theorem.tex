\chapter*{The Mean Value Theorem}

\begin{definition}
  Let $f$ be a differentiable function. A \textbf{critical point} of $f$ is a number $c$ such that
  \[f^\prime(c) = 0.\]
\end{definition}

\begin{definition}
  We shall say that $c$ is a \textbf{maximum point} of the function $f$ if and only if $f(c) \ge f(x)$ for all numbers $x$ at which $f$ is defined. If the condition $f(c) \ge f(x)$ holds for all numbers $x$ in some interval, then we say that the function has a maximum at $c$ in that interval. We call $f(c)$ a maximum value.
\end{definition}

\begin{definition}
  A \textbf{minimum point} for $f$ is a number $c$ such that $f(c) \le f(x)$ for all $x$ where $f$ is defined. A minimum value for the function is the value $f(c)$, taken at a minimum point.
\end{definition}

We see that the definitions for maximum and minimum points are analogous. Similarly, the next two definitions are analogous.

We shall say that a point $c$ is a \textbf{local minimum} or \textbf{relative minimum} of the function $f$ if there exists an interval $a_1 < c < b_1$ such that $f(c) \le f(x)$ for all numbers $x$ with $a_1 \le x \le b_1$.

\begin{theorem}
  Let $f$ be a continuous function over a closed interval $[a,b]$. Then there exists a point in the interval where $f$ has a maximum, and there exists a point where $f$ has a minimum.
\end{theorem}

\begin{theorem}
  Let $f$ be a continuous function on the interval $[a,b]$. Let $\alpha = f(a)$ and $\beta = f(b)$. Let $\gamma$ be a number between $\alpha$ and $\beta$. Then there exists a number $c$ such that $a < c < b$ and such that
  \[f(c) = \gamma.\]
\end{theorem}

\begin{theorem}
  Let $f$ be a function which is defined and differentiable in the open interval $a < x < b$. Let $c$ be a number in the interval at which the function has a local maximum or a local minimum. Then
  \[f^\prime(c) = 0.\]
\end{theorem}

We must assume that $f$ is differentiable because we will differentiate in the proof. There exists local minima $c$ and local maxima $c_0$ in $(a,b)$ by Theorem 1.1. Then $c$ is a critical point. We now prove this theorem.

\begin{proof}
  We give the proof in the case of a local maximum. Taking small values of $h$, positive or negative, the number $c + h$ will lie in the interval. This is true because in terms of distance, since $c$ is not equal to $a$ or $b$, then there must be points between $c$ and $a$ or $b$. We take $h$ to be positive to determine the limit from the right.

  Since we assume $c$ is a point where $f$ has a local maximum, then $f(c) \ge f(x)$ for all $x$ in this interval. As $c + h \ne c$, then $f(c) \ge f(c + h)$. Therefore
  \[f(c + h) - f(c) \le 0.\]
  Since we took $h$ to be positive, the Newton quotient satisfies
  \[\frac{f(c + h) - f(c)}{h} \le 0.\]
  Taking the limit as $h$ approaches $0$, we find that it is nonnegative.

  Now take $h$ to be negative, say $h = -k$ with $k > 0$. Then
  \[f(c - k) - f(c) \le 0.\]
  Hence
  \[\frac{f(c - k) - f(c)}{-k} = \frac{f(c) - f(c - k)}{k}.\]
  Taking the limit as $h$ approaches $0$, we also find that it is nonnegative. Both limits exist and are equal to $0$. Therefore the derivative of $f$ at $c$ is $0$, thus $c$ is a critical point. The case of a local minimum is analogous, and the proof is concluded.
\end{proof}

Let $f$ be a function defined on some interval.

\begin{definition}
  We shall say that $f$ is increasing over this interval if
  \[f(x_1) \le f(x_2)\]
  whenever $x_1$ and $x_2$ are two points of the interval such that
  \[x_1 \le x_2.\]
\end{definition}

We say that a function defined on some interval is decreasing over this interval if
\[f(x_1) \ge f(x_2)\]
whenever $x_1$ and $x_2$ are two points of the interval such that
\[x_1 \le x_2.\]

Observe that a constant function is both increasing and decreasing.

A function $f$ is strictly increasing if $x_1 < x_2$ implies $f(x_1) < f(x_2)$ and $f$ is strictly decreasing if $x_1 < x_2$ implies $f(x_1) > f(x_2)$.

Before stating the next theorem, know that if a function is differentiable over an interval $[a,b]$, then for example, the left derivative at $b$ exists but the right derivative does not. Hence there is no derivative at $b$ and analogous logic applies for $a$.

\begin{theorem}
  Let $f$ be a function which is continuous in some interval, and differentiable in the interval (excluding the end points).

  If $f^\prime(x) > 0$ in the interval (excluding the end points), then $f$ is strictly increasing.

  If $f^\prime(x) < 0$ in the interval (excluding the end points), then $f$ is strictly decreasing.

  If $f^\prime(x) = 0$ in the interval (excluding the end points), then $f$ is constant.
\end{theorem}

Suppose we have two functions $f$ and $g$ over a certain interval $[a,b]$ and we assume that $f,g$ are differentiable. Suppose that $f(a) \le g(a)$, and that $f^\prime(x) \le g^\prime(x)$ throughout the interval. Then $f(x) \le g(x)$ in the interval.

\begin{proof}
  We let
  \[h(x) = g(x) - f(x).\]
  Then by assumption (because we assume $f^\prime(x) \le g^\prime(x)$ in the proposition statement)
  \[h^\prime(x) = g^\prime - f^\prime \ge 0,\]
  so $h$ is increasing in the interval. Since
  \[h(a) = g(a) - f(a) \ge 0,\]
  it follows that $h(x) \ge 0$ throughout the interval, whence
  \[g(x) \ge f(x).\]
\end{proof}

\begin{theorem}
  Let $f(x)$ and $g(x)$ be two functions which are differentiable in some interval and assume that
  \[f^\prime(x) = g^\prime(x)\]
  for all $x$ in the interval. Then there is a constant $C$ such that
  \[f(x) = g(x) + C\]
  for all $x$ in the interval.
\end{theorem}

\begin{proof}
  Let $h(x) = f(x) - g(x)$ be the difference of our two functions. Then
  \[h^\prime(x) = f^\prime(x) - g^\prime(x) = 0.\]
  Hence $h(x)$ is constant by Theorem 2.1, that is $h(x) = C$ for some number $C$ and all $x$. This proves the theorem.
\end{proof}

\textbf{Example.} Determine the intervals on which
\[f(x) = x^2 - x + 5\]
increases and decreases.

The solution is given by Theorem 2.1. We must find the intervals at which the derivative is positive and negative. These intervals correspond to the function strictly increasing and strictly decreasing. But we must also find the intervals where $f$ is constant to satisfy the definitions of increasing and decreasing.

The derivative of $f$ is $2x - 1$. We first find the intervals such that the derivative is positive. We have that $2x - 1 > 0 \Leftrightarrow x > 1/2$. Next we find the intervals of $x$ such that the derivative is negative. We have that $2x - 1 < 0 \Leftrightarrow x < 1/2$. We see there is only one interval where $f$ increases and only one interval where $f$ decreases. The derivative is $0$ at $x = 1/2$. Hence $f$ is constant at $1/2$ and is also increasing and decreasing at $1/2$. Thus $f$ is increasing $x \ge 1/2$ and decreasing at $x \le 1/2$.

\textbf{Example.} Determine the intervals on which
\[x^3 + x - 2\]
increases and decreases.

The derivative of $f$ is $3x^2 + 1$. Determine where the derivative is positive to find when the function is increasing. We apply logic to find this result. Since $x^2 \ge 0$ for all $x$, then so is $3x^2$. Adding $1$ to this expression leaves it always positive without the possibility of being $0$. Hence $3x^2 + 1 > 0$ for all $x$. Therefore $f$ increases at all $x$, and consequently is never decreasing for any $x$.

\textbf{Example.} Determine the intervals on which
\[-x^3 + 2x + 1\]
increases and decreases.

The derivative of $f$ is $-3x^2 + 2$. We find where $f$ increases. We have $-3x^2 + 2 \ge 0 \Leftrightarrow |x| \le \sqrt{2/3}$. We perform a case analysis. Suppose $x < 0$. Then $-x \le \sqrt{2/3} \Leftrightarrow x \ge -\sqrt{2/3}$. Suppose $x \ge 0$. Then $x \le \sqrt{2/3}$. Together, this means that $f$ increases for $-\sqrt{2/3} \le x \le \sqrt{2/3}$.

Now we find where $f$ decreases. We have $-3x^2 + 2 \le 0 \Leftrightarrow |x| \ge \sqrt{2/3}$. We perform a case analysis. Suppose $x < 0$. Then $-x \ge \sqrt{2/3} \Leftrightarrow x \le -\sqrt{2/3}$. Suppose $x \ge 0$. Then $x \ge \sqrt{2/3}$. Together, this means that $f$ decreases at \textit{both} $x \ge -\sqrt{2/3}$ \textit{and} $x \ge \sqrt{2/3}$. We can also say that $f$ decreases at \textit{either} $x \le -sqrt{2/3}$ \textit{or} $x \ge \sqrt{2/3}$.

\textbf{Example.} Sketch the graph of the parabola $f(x) = x^2 - x - 1$.

We must determine when $f$ increases and decreases. This is given by the derivative $2x - 1$. The function increases for $x >= 1/2$ and decreases at $x \le 1/2$. The critical point is at $1/2$. Hence $1/2$ is the minimum point of $f$. The minimum value is then $f(1/2) = -5/4$. There exists two numbers $c$ such that $f(c) = 0$, called the roots, and are $(1 \pm \sqrt{5})/2$. Hence the curve intersects the $x$-axis at these roots. As for the $y$-axis, the curve intersects it at $f(0) = -1$. This is the best description we can give at this point.

\textbf{Example.} Prove
\[1 - \frac{x^2}{2} \le \cos x.\]

We must refer to the proposition on proving inequalities between functions. We prove that over a certain interval $[a,b]$, that $f(a) \le g(a)$ and $f^\prime(x) \le g^\prime(x)$ over that interval.

Let $f(x) = \cos x - (1 - x^2/2)$. Then $f^\prime(x) = x - sin x$. We know that $x - \sin x \ge 0$ for all $x \ge 0$. Hence $f^\prime(x) \ge 0$ for all $x \ge 0$. Furthermore, $f(0) = 0$. Consequently, this proves the proposition.

\textbf{Example.} Prove
\[x - \frac{x^3}{3 \cdot 2} \le \sin x\]
for all $x \ge 0$.

Let $f(x) = \sin x - (x - x^3/(3 \cdot 2))$. Then
\[f^\prime(x) = \cos x - (1 - \frac{x^2}{2}).\]
By the previous example, we have that $f^\prime(x) \ge 0$ for all $x \ge 0$. Furthermore,
\[f(0) = 0.\]
This proves the proposition.

\textbf{Example.} Prove that
\[t + \frac{1}{t} \ge 2\]
for $t > 0$.

Let $f(t) = t + 1/t$. Then $f^\prime(t) = 1 + \frac{-1}{t^2}$. For $0 < t \le 1$, we have that $-1/t^2$ decreases as $t$ increases. Hence $f$ decreases in this interval. But
\[f(1) = 2.\]
Thus the inequality holds (despite $f$ decreasing at this interval). For $t > 1$, the expression $-1/t^2$ decreases and is $< 1$. Hence $f(t) = 1 - 1/t^2 > 0$ for $t > 1$. Hence $f$ increases in this interval. For both intervals, which merged is $t > 0$, the inequality holds and the proposition is proven.

\begin{theorem}
  Let $a, b$ be two numbers, $a < b$. Let $f$ be a function which is continuous over the closed interval
  \[a \le x \le b\]
  and differentiable on the open interval $a < x < b$. Assume that
  \[f(a) = f(b) = 0.\]
  Then there exists a point $c$ such that
  \[a < c < b\]
  and such that $f^\prime(c) = 0$.
\end{theorem}

\begin{proof}
  If the function is constant in the interval, then its derivative is $0$ and any point in the open interval $a < x < b$ will do.

  If the function is not constant, then there exists some point in the interval where the function is not $0$, and this point cannot be one of the end points $a$ or $b$. Suppose that some value of our function is positive. By Theorem 1.1, the function has a maximum at a point $c$. Then $f(c)$ must be greater than $0$, and $c$ cannot be either one of the end points because $f(a) = f(b) = 0$. Consequently
  \[a < c < b.\]
  By Theorem 1.3, we must have $f^\prime(c) = 0$. This proves our theorem in case the function is positive somewhere in the interval.

\end{proof}
