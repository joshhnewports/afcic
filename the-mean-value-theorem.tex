\chapter*{The Mean Value Theorem}

\begin{definition}
  Let $f$ be a differentiable function. A \textbf{critical point} of $f$ is a number $c$ such that
  \[f^\prime(c) = 0.\]
\end{definition}

\begin{definition}
  We shall say that $c$ is a \textbf{maximum point} of the function $f$ if and only if $f(c) \ge f(x)$ for all numbers $x$ at which $f$ is defined. If the condition $f(c) \ge f(x)$ holds for all numbers $x$ in some interval, then we say that the function has a maximum at $c$ in that interval. We call $f(c)$ a maximum value.
\end{definition}

\begin{definition}
  A \textbf{minimum point} for $f$ is a number $c$ such that $f(c) \le f(x)$ for all $x$ where $f$ is defined. A minimum value for the function is the value $f(c)$, taken at a minimum point.
\end{definition}

We see that the definitions for maximum and minimum points are analogous. Similarly, the next two definitions are analogous.

We shall say that a point $c$ is a \textbf{local minimum} or \textbf{relative minimum} of the function $f$ if there exists an interval $a_1 < c < b_1$ such that $f(c) \le f(x)$ for all numbers $x$ with $a_1 \le x \le b_1$.

\begin{theorem}
  Let $f$ be a continuous function over a closed interval $[a,b]$. Then there exists a point in the interval where $f$ has a maximum, and there exists a point where $f$ has a minimum.
\end{theorem}

\begin{theorem}
  Let $f$ be a continuous function on the interval $[a,b]$. Let $\alpha = f(a)$ and $\beta = f(b)$. Let $\gamma$ be a number between $\alpha$ and $\beta$. Then there exists a number $c$ such that $a < c < b$ and such that
  \[f(c) = \gamma.\]
\end{theorem}

\begin{theorem}
  Let $f$ be a function which is defined and differentiable in the open interval $a < x < b$. Let $c$ be a number in the interval at which the function has a local maximum or a local minimum. Then
  \[f^\prime(c) = 0.\]
\end{theorem}

We must assume that $f$ is differentiable because we will differentiate in the proof. There exists local minima $c$ and local maxima $c_0$ in $(a,b)$ by Theorem 1.1. Then $c$ is a critical point. We now prove this theorem.

\begin{proof}
  We give the proof in the case of a local maximum. Taking small values of $h$, positive or negative, the number $c + h$ will lie in the interval. This is true because in terms of distance, since $c$ is not equal to $a$ or $b$, then there must be points between $c$ and $a$ or $b$. We take $h$ to be positive to determine the limit from the right.

  Since we assume $c$ is a point where $f$ has a local maximum, then $f(c) \ge f(x)$ for all $x$ in this interval. As $c + h \ne c$, then $f(c) \ge f(c + h)$. Therefore
  \[f(c + h) - f(c) \le 0.\]
  Since we took $h$ to be positive, the Newton quotient satisfies
  \[\frac{f(c + h) - f(c)}{h} \le 0.\]
  Taking the limit as $h$ approaches $0$, we find that it is nonnegative.

  Now take $h$ to be negative, say $h = -k$ with $k > 0$. Then
  \[f(c - k) - f(c) \le 0.\]
  Hence
  \[\frac{f(c - k) - f(c)}{-k} = \frac{f(c) - f(c - k)}{k}.\]
  Taking the limit as $h$ approaches $0$, we also find that it is nonnegative. Both limits exist and are equal to $0$. Therefore the derivative of $f$ at $c$ is $0$, thus $c$ is a critical point. The case of a local minimum is analogous, and the proof is concluded.
\end{proof}

Let $f$ be a function defined on some interval.

\begin{definition}
  We shall say that $f$ is increasing over this interval if
  \[f(x_1) \le f(x_2)\]
  whenever $x_1$ and $x_2$ are two points of the interval such that
  \[x_1 \le x_2.\]
\end{definition}

We say that a function defined on some interval is decreasing over this interval if
\[f(x_1) \ge f(x_2)\]
whenever $x_1$ and $x_2$ are two points of the interval such that
\[x_1 \le x_2.\]

Observe that a constant function is both increasing and decreasing.

A function $f$ is strictly increasing if $x_1 < x_2$ implies $f(x_1) < f(x_2)$ and $f$ is strictly decreasing if $x_1 < x_2$ implies $f(x_1) > f(x_2)$.

Before stating the next theorem, know that if a function is differentiable over an interval $[a,b]$, then for example, the left derivative at $b$ exists but the right derivative does not. Hence there is no derivative at $b$ and analogous logic applies for $a$.

\begin{theorem}
  Let $f$ be a function which is continuous in some interval, and differentiable in the interval (excluding the end points).

  If $f^\prime(x) > 0$ in the interval (excluding the end points), then $f$ is strictly increasing.

  If $f^\prime(x) < 0$ in the interval (excluding the end points), then $f$ is strictly decreasing.

  If $f^\prime(x) = 0$ in the interval (excluding the end points), then $f$ is constant.
\end{theorem}

Suppose we have two functions $f$ and $g$ over a certain interval $[a,b]$ and we assume that $f,g$ are differentiable. Suppose that $f(a) \le g(a)$, and that $f^\prime(x) \le g^\prime(x)$ throughout the interval. Then $f(x) \le g(x)$ in the interval.

\begin{proof}
  We let
  \[h(x) = g(x) - f(x).\]
  Then by assumption (because we assume $f^\prime(x) \le g^\prime(x)$ in the proposition statement)
  \[h^\prime(x) = g^\prime - f^\prime \ge 0,\]
  so $h$ is increasing in the interval. Since
  \[h(a) = g(a) - f(a) \ge 0,\]
  it follows that $h(x) \ge 0$ throughout the interval, whence
  \[g(x) \ge f(x).\]
\end{proof}

\begin{theorem}
  Let $f(x)$ and $g(x)$ be two functions which are differentiable in some interval and assume that
  \[f^\prime(x) = g^\prime(x)\]
  for all $x$ in the interval. Then there is a constant $C$ such that
  \[f(x) = g(x) + C\]
  for all $x$ in the interval.
\end{theorem}

\begin{proof}
  Let $h(x) = f(x) - g(x)$ be the difference of our two functions. Then
  \[h^\prime(x) = f^\prime(x) - g^\prime(x) = 0.\]
  Hence $h(x)$ is constant by Theorem 2.1, that is $h(x) = C$ for some number $C$ and all $x$. This proves the theorem.
\end{proof}
